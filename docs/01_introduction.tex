% На сегодняшний день огромное число задач машинного обучения решено при помощи нейросетевых моделей.
% Более того state-of-the-art результаты показывают именно нейросетевые модели и подходы глубокого обучения. 
% Не исключением являются задачи natural language processing (NLP).
% Например, задачи sentiment analysis, question answering \cite{t5}, language modelling \cite{gpt3} и другие решены при помощи нейросетевых моделей.
% В большинстве случаев такие модели имеют десятки или сотни миллиардов параметров, из-за чего их либо очень дорого или просто не возможно обучать с нуля самостоятельно \cite{gpt3, t5}.  
% Также становится всё больше и больше задач, которые в качестве метрик качества используют нейросетевые модели из других задач. 
% Это приводит к желанию использовать эти нейросетевые модели не только в качестве метрик качества, но также в качестве функций потерь, так как это позволит напрямую оптимизировать целевую метрику. 
% Но в задачах NLP возникает проблема связанная с тем, что в большинстве случаев у обучаемой модели и оценочной модели будут различаться токенизаторы. 
% Это приводит к тому, что теряется дифференцируемость такого функционала, так как сперва необходимо получить текст от обучаемой модели при помощи $\arg\max$, далее разбить полученный текст на токены при помощи токенизатора оценочной модели. 
% Обе операции нарушают дифференцируемость, а основная проблема заключается в том, что
% токены одного токенизатора не могут инъективно отобразиться в токены другого токенизатора.

% Схожая проблема, связанная с потерей дифференцируемости, возникает в задачах генерации текстов при помощи порождающих моделей \cite{gan-bert, gan-wo-rl}.
% Дабы решить эту проблему одни подходы используют идеи из Reinforcement Learning \cite{Yu_Zhang_Wang_Yu_2017}, основанные на аппроксимации градиентов и методе Монте-Карло.
% Другие подходы используют идею gumbel-softmax для апроксимации one-hot векторов полученных предложений \cite{kusner2016gans}.
% Но основная проблема дифференцируемости в этих работах связана с операцией $\arg\max$, в то время как в данной работе всё сводится к различным токенизаторам модели-детоксификатора и оценочной модели. 


% В данной работе рассматривается задача детоксификации тектов.
% Требуется для токсичного предложения сгенерировать нейтральную его версию. 
% Под токсичностью в большинстве случаев подразумевается наличие обсценной лексики.
% Задачу можно рассматривать, как задачу стилизации текстов. 
% В качестве одной из основных метрик качества используется нейросетевая модель~--- Style Transfer Accuracy (STA), оценивающая степень токсичности предложения. 
% Использование нейросетевой модели приводит к описанным ранее проблемам. 
% Предлагается обучить \textit{адаптер}, который заменит эмбеддинг слой оценочной модели.
% Адаптер~--- это линейный слой, который на вход принимает распределения вероятностей токенов, выданных моделью-детоксификатором, и возвращает аппроксимацию входных эмбеддингов оценочной модели. 
% Данная работа описывает алгоритм обучения адаптера и модели-детоксификатора.
% Благодаря предложенному методу удалось добиться прироста метрики STA на $7\%$ и увеличить целевую метрики на $4\%$, представляющую собой произведение STA и chrF1 \cite{popovic-2015-chrf}.
% Также в работе описывается процесс нахождения оптимального алгоритма обучения адаптера и детоксификатора, демонстрируются полученные результаты при использовании различных подходов.  


На сегодняшний день для решения задач в области обработки естественного языка активно используется подход переноса обучения (transfer learning). 
Глубокие нейросетевые модели на основе архитектуры трансформер \cite{gpt3, t5} предобучаются на большом корпусе текстов, а затем дообучаются на целевую задачу (не обязательно совпадающую с задачей предобучения). 

В последнее время начинает набирать популярность использование предобученных моделей в качестве метрик качества в задачах генерации текста. 
Далее мы будем называть такие модели \textit{оценивающими}, а модели решающие основную задачу~--- \textit{целевыми}. 
Сгенерированный целевой моделью текст подаётся на вход оценивающей модели, решающей определённую задачу, а её результат используется в качестве значения метрики качества. Например, в задаче текстовой стилизации в качестве оценочной модели может использоваться модель, оценивающая естественность полученного текста на основе XLM-R\cite{conneau2019unsupervised, briakou-etal-2021-evaluating}.
% Можно ещё написать, почему такой подход хорош (сравнение с BLEU, проблема синонимов, подгонки под эталоны и т.п.) и почему плох (что модели лажают и результат может не показывать реальное качество).

Возникает естественный вопрос: можно ли использовать предобученную модель не только для оценивания качества целевой модели, но и для её обучения? 
Возможно ли сконструировать функцию потерь, на основе весов оценивающей модели, улучшающую качество решения целевой задачи? 
В данной работе рассматриваются эти вопросы на примере задачи детоксификации текста.

Детоксификация текста - это задача текстовой стилизации, где требуется по токсичному предложению построить его нейтральный вариант.
Под токсичностью в большинстве случаев подразумевается наличие обсценной лексики.
Задача детоксификации можно поставить как задачу машинного перевода(sequence-to-sequence), где на вход модели подаётся токсичный текст, а на выходе генерируется нейтральный вариант. 
Основная архитектура для решения таких задач - энкодер-декодер на основе трансформера\cite{t5}. 
Кодировщик трансформера принимает на вход последовательность BPE-токенов (символьные n-граммы) из ограниченного множества, называемого словарём, и кодирует их в последовательность векторов. 
Декодировщик трансформера, используя выходы кодировщика, генерирует токены по очереди в авторегрессионной манере.

Наивный способ использования оценивающей модели для задания функции потерь~--- подать выходы декодировщика на вход этой модели, а затем сопоставить выходное значение оценивающей модели с значением для истинного результирующего предложения. 
Например, если модель оценивает токсичность предложения по шкале от нуля до единицы, выход модели должен быть близок к нулю.

Такой подход имеет огромный минус~--- если между токенами словарей моделей нет инъективного отображения, получившаяся композиция моделей не будет дифференцируема, и обучение градиентными методами будет невозможно. 
На практике инъективность отображения встречается только при полном совпадении словарей, например, если до начала обучения задать словарь целевой модели равным словарю оценивающей модели. 
Проблема такого подхода в том, что это делает невозможным использование предобученных моделей (если у них не совпадает словарь с оценивающей моделью) для инициализации весов целевой модели, что может серьёзно сказаться на итоговом качестве.

Схожая проблема, связанная с потерей дифференцируемости, возникает в задачах генерации текстов при помощи порождающих моделей \cite{gan-bert, gan-wo-rl}.
Дабы решить эту проблему одни подходы используют идеи обучения с подкреплением \cite{Yu_Zhang_Wang_Yu_2017}, основанные на аппроксимации градиентов и методе Монте-Карло.
Другие подходы используют идею gumbel-softmax для апроксимации one-hot векторов полученных предложений \cite{kusner2016gans}.
Но основная проблема дифференцируемости в этих работах связана с операцией $\arg\max$, в то время как в данной работе всё сводится к различным словарям детоксификатора и оценочной модели. 
Единственный подход, который можно попробовать использовать,~--- идея обучения с подкрепление, но в описанных работах он показывает плохие результаты и труден в обучении. 

В данной работе описан способ использования оценивающей модели в качестве функции потерь, не накладывающий требования на словарь целевой модели. 
Предлагается во время обучения заменить входной эмбеддинг-слой оценивающей модели на линейный слой, называемый \textit{адаптером}.
Адаптер принимает на вход распределения вероятностей токенов, выданных моделью-детоксификатором, и возвращает аппроксимацию входных эмбеддингов оценочной модели. 
Для обучения адаптера используется функция потерь в виде дивергенции Кульбака-Лейблера, которая принимает вероятность токсичности для истинного предложения при использовании оценочной модели и вероятность токсичности детоксифицированного при использовании оценочной модели с адаптером.
Кроме того данная работа описывает алгоритм обучения адаптера и модели-детоксификатора.
Благодаря предложенному методу удалось добиться прироста метрики, заданной оценочной моделью, и увеличить целевую метрики, представляющую собой произведение метрики оценочной модели и chrF1 \cite{popovic-2015-chrf}.