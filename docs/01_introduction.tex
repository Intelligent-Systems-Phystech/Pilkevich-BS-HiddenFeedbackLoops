На сегодняшний день огромное число задач машинного обучения решено при помощи нейросетевых моделей.
Более того state-of-the-art результаты показывают именно нейросетевые модели и подходы глубокого обучения. 
Не исключением являются задачи natural language processing (NLP).
Например, задачи sentiment analysis, question answering \cite{t5}, language modelling \cite{gpt3} и другие решены при помощи нейросетевых моделей.
В большинстве случаев такие модели имеют десятки или сотни миллиардов параметров, из-за чего их либо очень дорого или просто не возможно обучать с нуля самостоятельно \cite{gpt3, t5}.  
Также становится всё больше и больше задач, которые в качестве метрик качества используют нейросетевые модели из других задач. 
Это приводит к желанию использовать эти нейросетевые модели не только в качестве метрик качества, но также в качестве функций потерь, так как это позволит напрямую оптимизировать целевую метрику. 
Но в задачах NLP возникает проблема связанная с тем, что в большинстве случаев у обучаемой модели и оценочной модели будут различаться токенизаторы. 
Это приводит к тому, что теряется дифференцируемость такого функционала, так как сперва необходимо получить текст от обучаемой модели при помощи $\arg\max$, далее разбить полученный текст на токены при помощи токенизатора оценочной модели. 
Обе операции нарушают дифференцируемость, а основная проблема заключается в том, что
токены одного токенизатора не могут инъективно отобразиться в токены другого токенизатора.

Схожая проблема, связанная с потерей дифференцируемости, возникает в задачах генерации текстов при помощи порождающих моделей \cite{gan-bert, gan-wo-rl}.
Дабы решить эту проблему одни подходы используют идеи из Reinforcement Learning \cite{Yu_Zhang_Wang_Yu_2017}, основанные на аппроксимации градиентов и методе Монте-Карло.
Другие подходы используют идею gumbel-softmax для апроксимации one-hot векторов полученных предложений \cite{kusner2016gans}.
Но основная проблема дифференцируемости в этих работах связана с операцией $\arg\max$, в то время как в данной работе всё сводится к различным токенизаторам модели-детоксификатора и оценочной модели. 


В данной работе рассматривается задача детоксификации тектов.
Требуется для токсичного предложения сгенерировать нейтральную его версию. 
Под токсичностью в большинстве случаев подразумевается наличие обсценной лексики.
Задачу можно рассматривать, как задачу стилизации текстов. 
В качестве одной из основных метрик качества используется нейросетевая модель~--- Style Transfer Accuracy (STA), оценивающая степень токсичности предложения. 
Использование нейросетевой модели приводит к описанным ранее проблемам. 
Предлагается обучить \textit{адаптер}, который заменит эмбеддинг слой оценочной модели.
Адаптер~--- это линейный слой, который на вход принимает распределения вероятностей токенов, выданных моделью-детоксификатором, и возвращает аппроксимацию входных эмбеддингов оценочной модели. 
Данная работа описывает алгоритм обучения адаптера и модели-детоксификатора.
Благодаря предложенному методу удалось добиться прироста метрики STA на $7\%$ и увеличить целевую метрики на $4\%$, представляющую собой произведение STA и chrF1 \cite{popovic-2015-chrf}.
Также в работе описывается процесс нахождения оптимального алгоритма обучения адаптера и детоксификатора, демонстрируются полученные результаты при использовании различных подходов.  