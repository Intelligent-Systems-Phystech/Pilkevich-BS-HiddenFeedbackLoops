Данная работа предлагает метод использования обученных нейросетевых моделей в качестве функции потерь в задачах обработки естественного языка.
Предложенный метод решает проблему отсутствия дифференцируемости такой функции потерь, возникающей из-за различных словарей токенизаторов оценочной и целевой модели, которая может инициализироваться предобученной моделью.
Описанная проблема и предложенный метод рассматривались для задачи детоксификации текстов.
Предложенный подход доказывает свою работоспособность и эффективность на основе результатов проведенных экспериментов.  
Также опубликован код для воспроизведение финального подхода\footnote{\url{https://github.com/Intelligent-Systems-Phystech/Pilkevich-BS-Thesis}}

В последующих работах необходимо обобщить предложенный метод на другие оценочные модели. 
Также требуется проверить работоспособность метода в других задачах.
Отдельный интерес представляет сравнение с методами из текстовых порождающих моделей в текущей постановке задачи, так и сравнение предложенного метода для задачи генерации текстов против текущих подходов порождающих моделей. 