\begin{abstract}

Один из способов оценки качества в задачах генерации текста~--- использование предобученной (например, на задачу классификации) глубокой нейросетевой модели.
Например, модель, решающая задачу определения токсичности текста, может использоваться для оценки качества задачи детоксификации текста.
Логично предположить, что оценивающую модель следует использовать для задания функции потерь, чтобы улучшить качество решения.
Нейросетевые модели для обработки текста работают с ограниченным словарём входных токенов, и у разных моделей словарь может отличаться. 
В силу отсутствия инъективного отображения между токенами моделей, наивный способ использования оценивающей модели поверх результатов основной невозможен. 
Данная работа предлагает способ решения отсутствия дифференцируемости такой функции потерь на примере задачи детоксификации текстов.  
Предлагается обучить новый входной эмбеддинг-слой оценочной модели, называемый адаптером, который будет принимать распределения вероятностей токенов, выданных моделью детоксификатором.
В работе предложен способ обучения адаптера с использованием в качестве функции потерь дивергенции Кульбака-Лейблера между истинной вероятностью токсичности и вероятностью, полученной при использовании адаптера. 
Также предложен способ одновременного обучения детоксификатора и адаптера, приводящие к улучшению качества модели. 
Проведенные эксперименты показывают эффективность предложенного метода

\end{abstract}