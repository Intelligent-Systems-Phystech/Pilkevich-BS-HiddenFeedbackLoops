\subsection{Задача стилизации}

Задачу текстовой стилизации для параллельного корпуса текстов можно рассматривать, как задачу машинного перевода. 
Поэтому можно использовать методы и подходы для задачи seq-to-seq. 
Данная работа в качестве базового решение задачи детоксификации основывается на таком подходе, дообучая трансформер T5 \cite{t5}.
Но при таком подходе никак не учитывается корректность пар в датасете, точное соответствие заданному стилю и насколько расплывчаты "границы" заданного стиля.
Поэтому важной составляющей задачи стилизации является факт, что семантический смысл любого текста может быть выражен в любом стиле \cite{Tikhonov2018WhatIW}.   

\subsection{Автоматическая оценка качества стилизации}
Одной из составляющих качества задачи стилизации и машинного перевода является оценка сохранения смысла. 
Для случая параллельных корпусов текстов хорошо себя показывает chrF \cite{popovic-2015-chrf}.
Он зачастую демонстрирует высокую корреляцию с человеческой оценкой качества сохранения смысла \cite{briakou-etal-2021-evaluating, logacheva-etal-2022-study}. 
Но данная метрика никак не учитывает стиль получаемых предложений.
За соответствие стилю хорошо себя показывают нейросетевые подходы \cite{briakou-etal-2021-evaluating}. 
Но при этом для случая детоксификации русско-язычных текстов такой подход слабо коррелировал с челоческими оценками \cite{logacheva-etal-2022-study}.

\subsection{Текстовые порождающие модели}
Схожая проблема "потери" дифференцируемости встречается у текстовых порождающих моделях. 
Проблема заключается в том, что дексриминатор должен работать с последовательностью токенов на входе. 
Но чтобы получить последовательность токенов необходимо применить операцию $\arg\max$ для выхода генератора, что приводит к отсутствию дифференцируемости. 
Дабы решить эту проблему одни подходы предлагают использовать reinforcement learning \cite{Yu_Zhang_Wang_Yu_2017}, gumbel-softmax \cite{kusner2016gans} и другие "ухищрения" \cite{gan-wo-rl, gan-bert}.
При этом отличительная особенность проблемы дифференцируемости в данной работы заключается в том, что параметры, словарь токенов $V_{g}$ и токенизатор $\tau_{g}$ оценочной модели $g_{\text{toxic}}$ фиксированы, а также зафиксирован словарь $V_{f}$ и токенизатор $\tau_{g}$ детоксификатора $f_{\theta}$. 
Наиболее простым подходом для реализации в данной работы является RL-подход, но зачастую он показывает плохие результаты для порождающих моделей и сложен в обучении.
Поэтому был предложен подход с использованием адаптера, который будет описан в следующей главе. 
