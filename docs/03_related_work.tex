\subsection{Задача стилизации}

Как было описано ранее, задачу текстовой стилизации для параллельного корпуса текстов можно рассматривать, как задачу машинного перевода. 
Данная работа в качестве базового решение задачи детоксификации основывается на таком подходе, дообучая трансформер T5 \cite{t5}.
Но при таком подходе никак не учитывается корректность пар в датасете, точное соответствие заданному стилю и насколько расплывчаты <<границы>> заданного стиля.
Поэтому важной составляющей задачи стилизации является факт, что семантический смысл любого текста может быть выражен в любом стиле \cite{Tikhonov2018WhatIW}.   

\subsection{Автоматическая оценка качества стилизации}
\label{section:autoeval}
Одной из составляющих качества задачи стилизации и машинного перевода является оценка сохранения смысла. 
Для случая параллельных корпусов текстов хорошо себя показывает chrF \cite{popovic-2015-chrf}.
Он зачастую демонстрирует высокую корреляцию с человеческой оценкой качества сохранения смысла \cite{briakou-etal-2021-evaluating, logacheva-etal-2022-study}. 
Но данная метрика никак не учитывает стиль получаемых предложений.
В качестве метрик, отвечающих за соответствие стилю, хорошо себя показывают нейросетевые подходы \cite{briakou-etal-2021-evaluating}. 
Но при этом для случая детоксификации русскоязычных текстов такой подход слабо коррелирует с человеческими оценками \cite{logacheva-etal-2022-study}.

\textbf{ChrF}~--- F-score на основе символьных $n$-грамм.
Введём chrP~--- доля символьных n-грамм из предлагаемого предложения, которые имеются в оригинальном.
И chrR~--- доля символьных n-грамм из оригинального предложения, которые представлены в предлагаемом. 
Тогда финальная формула:
\begin{gather*}
    \text{chrF}_{\beta} = (1 + \beta^2) \frac{\text{chrP} \cdot \text{chrR}}{\beta^2 \text{chrP} + \text{chrR}},
\end{gather*}
где chrP, chrR считаются как среднее по всем предложениям. 

В качестве метрики качества стилизации будем рассматривать \textbf{Style transfer accuracy (STA)}~--- вероятность токсичности предложения.
Метрика задаётся нейросетевой оценочной моделью $g_{\text{toxic}}$.
В качестве модели $g_{\text{toxic}}$ используется предобученный Conversational RuBERT\footnote{\url{https://huggingface.co/DeepPavlov/rubert-base-cased-conversational}}, дообученный на задачу определения токсичности\footnote{\url{https://huggingface.co/SkolkovoInstitute/russian_toxicity_classifier}}. 


\subsection{Текстовые порождающие модели}
Схожая проблема <<потери>> дифференцируемости встречается у текстовых порождающих моделях. 
Проблема заключается в том, что дискриминатор должен работать с последовательностью токенов на входе. 
Но чтобы получить последовательность токенов необходимо применить операцию $\arg\max$ для выхода генератора, что приводит к отсутствию дифференцируемости. 
Дабы решить эту проблему одни подходы предлагают использовать обучение с подкреплением \cite{Yu_Zhang_Wang_Yu_2017}, gumbel-softmax \cite{kusner2016gans} и другие <<ухищрения>> \cite{gan-wo-rl, gan-bert}.
При этом отличительная особенность проблемы дифференцируемости в данной работы заключается в том, что параметры, словарь токенов $V_{g}$ и токенизатор $\tau_{g}$ оценочной модели $g_{\text{toxic}}$ фиксированы, а также зафиксирован словарь $V_{f}$ и токенизатор $\tau_{g}$ детоксификатора $f_{\theta}$. 
Наиболее простым подходом для реализации в данной работы является RL-подход, но зачастую он показывает плохие результаты для порождающих моделей и сложен в обучении.
Поэтому был предложен подход с использованием адаптера, который будет описан в следующей главе. 
