# Оптимизация критерия заданного нейросетевой моделью в задаче детоксификации текста

**Автор:** Пилькевич Антон Александрович

**Консультант:** Попов Артём Сергеевич

## Аннотация


Один из способов оценки качества в задачах генерации текста~--- использование предобученной (например, на задачу классификации) глубокой нейросетевой модели.
Например, модель, решающая задачу определения токсичности текста, может использоваться для оценки качества задачи детоксификации текста.
Логично предположить, что оценивающую модель следует использовать для задания функции потерь, чтобы улучшить качество решения.
Нейросетевые модели для обработки текста работают с ограниченным словарём входных токенов, и у разных моделей словарь может отличаться. 
В силу отсутствия инъективного отображения между токенами моделей, наивный способ использования оценивающей модели поверх результатов основной невозможен. 
Данная работа предлагает способ решения отсутствия дифференцируемости такой функции потерь на примере задачи детоксификации текстов.  
Предлагается обучить новый входной эмбеддинг-слой оценочной модели, называемый адаптером, который будет принимать распределения вероятностей токенов, выданных моделью детоксификатором.
В работе предложен способ обучения адаптера с использованием в качестве функции потерь дивергенции Кульбака-Лейблера между истинной вероятностью токсичности и вероятностью, полученной при использовании адаптера. 
Также предложен способ одновременного обучения детоксификатора и адаптера, приводящие к улучшению качества модели. 
Проведенные эксперименты показывают эффективность предложенного метода


**Ключевые слова:** *deep learning, natural language processing, text style transfer.*

## Постановка задачи

### Задача
Детоксификация токсичных входных предложений к нейтральному варианту.
Под токсичностью в основном подразумевается обсценная лексика.
Данные представлены параллельным корпусом из токсичного предложения и его нейтральными вариантами. 
В качестве метрик качества используются:
- Style Transfer Accuracy (STA) -- выход предобученного Conversational RuBERT дообученного на задачу определения токсичности,
- chrF -- F-score на основе символьных n-грамм.

### Проблема
Для оценки качества детоксификации используется **нейросетевая модель** оценки токсичности.
Но эту модель нельзя использовать в качестве функции потерь из-за отличных токенизаторов у детоксификатора и оценочной модели, так как **теряется дифференцируемость**. 

### Решение
В данной работе предлагается переобучать входной эмбеддинг слой оценочной модели, который будет принимать вместо one-got векторов выходное распределение вероятностей токенов от модели детоксификатора. 

## Подготовка окружения для воспроизодимости

Вся работа с пакетами производится при помощи conda.

Алгортим настройки окружения:
1. Установка `anaconda`

2. Установка окружения
```bash
conda create -y -p ~/envs/<env_name> python=3.7 pip==21.2.2
```

3. Активируем окружение 
```bash
conda activate ~/envs/<env_name>
```

4. Установка дополнительных необходимых пакетов 
```bash
pip install -r requirements.txt
```

5. Добавление окружения в `jupyter`:
```bash
pip install ipykernel
python -m ipykernel install --user --name <env_name> --display-name <env_name>
```


Также для использовании [кода](/nlp_adapter) требутся сперва склонировать данный репозиторий локально. 
Перед началом запуска требуется добавить в `sys.path` локальный путь до репозиторий:
```python
import sys
sys.path = [<локальный путь до репозитория>/Pilkevich-BS-Thesis/] + sys.path
```

## Проведение эксперимента

Весь код для воспроизведения экспериментов представлен в виде [ноутбуков](/notebooks).
Результаты экспериментов представленных ноутбуков ( при использовании финальной версии предложенного метода ) отображены [таблице](/notebooks/results.md).
Все отсальные эксперименты, а также выводы отражены в [презентации](/docs/pres.pdf).

*Замечание.* В ноутбуках требуется указать корректные пути для *вас*.

## Исходный код

Исходный код, который описывает логику обучения и валидации моделей, расположен в [nlp_adapter](/nlp_adapter). 
Логически можно выделить две компоненты: [обучение](/nlp_adapter/train) и [валидаци](/nlp_adapter/evaluation). 

## Замечание

Данная работа основана на соревновании [Russian Text Detoxification Based on Parallel Corpora](https://russe.nlpub.org/2022/tox/).
Соответсветсвенно данные и часть кода позаимстоваваны из [репозитория](https://github.com/skoltech-nlp/russe_detox_2022) соревнования. 
