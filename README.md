# Оптимизация критерия заданного нейросетевой моделью в задаче детоксификации текста

**Автор:** Пилькевич Антон Александрович

**Консультант:** Попов Артём Сергеевич

## Аннотация


Часто нейросетевые модели используются в качестве метрик качества для задач обработки естественного языка.
Возникает желание использовать их в качестве функции потерь, чтобы явно оптимизировать заданную метрику.
Но в силу их неизменяемости появляется проблема с дифференцируемостью такой функции потерь, так как различные токенизаторы нарушают её.
В первую очередь это связано с тем, что отсутствует инъективное отображение между токенами двух токенизаторов: модели, решающей задачу, и оценочной модели.
Данная работа предлагает способ решения отсутствия дифференцируемости такой функции потерь на примере задачи детоксификации текстов.
Предлагается обучить новый входной эмбеддинг-слой оценочной модели, который будет принимать распределения вероятностей токенов, выданных моделью детоксификатором.
Это позволит использовать её в качестве функции потерь.
В работе описывается алгоритм одновременного обучения детоксификатора и адаптера.
Также приводятся эксперименты доказывающие эффективность предложенного метода.

**Ключевые слова:** *deep learning, natural language processing, text style transfer.*

## Постановка задачи

### Задача
Детоксификация токсичных входных предложений к нейтральному варианту.
Под токсичностью в основном подразумевается обсценная лексика.
Данные представлены параллельным корпусом из токсичного предложения и его нейтральными вариантами. 
В качестве метрик качества используются:
- Style Transfer Accuracy (STA) -- выход предобученного Conversational RuBERT дообученного на задачу определения токсичности,
- chrF -- F-score на основе символьных n-грамм.

### Проблема
Для оценки качества детоксификации используется **нейросетевая модель** оценки токсичности.
Но эту модель нельзя использовать в качестве функции потерь из-за отличных токенизаторов у детоксификаторра и оценочной модели, так как **теряется дифференцируемость**. 

### Решение
В данной работе предлагается переобучать входной эмбеддинг слой оценочной модели, который будет принимать вместо one-got векторов выходное распределение вероятностей токенов от модели детоксификатора. 

## Подготовка окружения для воспроизодимости

Вся работа с пакетами производится при помощи conda.

Алгортим настройки окружения:
1. Установка `anaconda`

2. Установка окружения
```bash
conda create -y -p ~/envs/<env_name> python=3.7 pip==21.2.2
```

3. Активируем окружение 
```bash
conda activate ~/envs/<env_name>
```

4. Установка дополнительных необходимых пакетов 
```bash
pip install -r requirements.txt
```

5. Добавление окружения в `jupyter`:
```bash
pip install ipykernel
python -m ipykernel install --user --name <env_name> --display-name <env_name>
```


Также для использовании [кода](/nlp_adapter) требутся сперва склонировать данный репозиторий локально. 
Перед началом запуска требуется добавить в `sys.path` локальный путь до репозиторий:
```python
import sys
sys.path = [<локальный путь до репозитория>/Pilkevich-BS-Thesis/] + sys.path
```

## Проведение эксперимента

Весь код для воспроизведения экспериментов представлен в виде [ноутбуков](/notebooks).
Результаты экспериментов представленных ноутбуков ( при использовании финальной версии предложенного метода ) отображены [таблице](/notebooks/results.md).
Все отсальные эксперименты, а также выводы отражены в [презентации](/docs/pres.pdf).

*Замечание.* В ноутбуках требуется указать корректные пути для *вас*.

## Исходный код

Исходный код, который описывает логику обучения и валидации моделей, расположен в [nlp_adapter](/nlp_adapter). 
Логически можно выделить две компоненты: [обучение](/nlp_adapter/train) и [валидаци](/nlp_adapter/evaluation). 

## Замечание

Данная работа основана на соревновании [Russian Text Detoxification Based on Parallel Corpora](https://russe.nlpub.org/2022/tox/).
Соответсветсвенно данные и часть кода позаимстоваваны из [репозитория](https://github.com/skoltech-nlp/russe_detox_2022) соревнования. 
