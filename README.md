# Оптимизация критерия заданного нейросетевой моделью в задаче детоксификации текста

**Автор:** Пилькевич Антон Александрович

**Консультант:** Попов Артём Сергеевич

## Аннотация

Сегодня огромное число языковых задач решено при помощи очень тяжелых нейросетевых моделей, которые дорого или не возможно переобучать. 
Причём эти нейросетевый модели часто используются в качестве метрик качества. 
Возникает желание использовать их в качестве функции потерь. 
Но в силу их неизменяемости появляется проблема с дифференцируемостью такой функции потерь, так как различные токенизаторы нарушают дифференцируемость.
В первую очередь это связано с тем, что отсутствует инъективное отображение между токенами двух токенизаторов.  
Данная работа предлагает способ решения этой проблемы на примере задачи детоксификации текстов. 
Предлагается обучить новый входной эмбеддинг слой(адаптер?) оценочной модели(?) на основе логитов модели детоксификатора. 
Это позволит использовать её в качестве функции потерь.
В работе описывается алгоритм одновременного обучения детоксификатора и адаптера.
Также приводятся эксперименты доказывающие эффективность предложенного метода.

**Ключевые слова:** *deep learning, natural language processing, text style transfer.*

## Постановка задачи

### Задача
Детоксификация токсичных входных предложений к нейтральному варианту.
Данные представлены параллельным корпусом из токсичного предложения и его нейтральными вариантами. 
В качестве метрик качества используются:
- Style Transfer Accuracy (STA) -- выход предобученного Conversational RuBERT дообученного на задачу определения токсичности,
- chrF -- F-мера на основе символьных n-грамм.

### Проблема
Для оценки качества детоксификации используется **нейросетевая модель** оценки токсичности.
Но эту модель нельзя использовать в качестве функции потерь из-за отличного токенайзера, так как **теряется дифференцируемость**. 

### Решение
В данной работе предлагается переобучать эмбеддинг слой лосс-модели, который будет принимать логиты модели детоксификатора. 

## Подготовка окружения для воспроизодимости

Вся работа с пакетами производится при помощи conda.

Алгортим настройки окружения:
1. Установка `anaconda`

2. Установка окрежения
```bash
conda create -y -p ~/envs/<env_name> python=3.7 pip==21.2.2
```

3. Активируем окружение 
```bash
conda activate ~/envs/<env_name>
```

4. Установка дополнительных необходимых пакетов 
```bash
pip install -r requirements.txt
```

5. Добавление окружения в `jupyter`:
```bash
pip install ipykernel
python -m ipykernel install --user --name <env_name> --display-name <env_name>
```


Также для использовании [кода](/nlp_adapter) требутся сперва склонировать данный репозиторий локально. 
Перед началом запуска требуется добавить в `sys.path` локальный путь до репозиторий:
```python
import sys
sys.path = [<локальный путь до репозитория>/Pilkevich-BS-Thesis/] + sys.path
```

## Проведение эксперимента

Весь код для воспроизведения экспериментов представлен в виде [ноутбуков](/notebooks).
Результаты экспериментов представленных ноутбуков ( при использовании финальной версии предложенного метода ) отображены [таблице](/notebooks/results.md).
Все отсальные эксперименты, а также выводы отражены в [презентации](/docs/pres.pdf).

*Замечание.* В ноутбуках требуется указать корректные пути для *вас*.

## Исходный код

Исходный код, который описывает логику обучения и валидации моделей, расположен в [nlp_adapter](/nlp_adapter). 
Логически можно выделить две компоненты: [обучение](/nlp_adapter/train) и [валидаци](/nlp_adapter/evaluation). 

## Замечание

Данная работа основана на соревновании [Russian Text Detoxification Based on Parallel Corpora](https://russe.nlpub.org/2022/tox/).
Соответсветсвенно данные и часть кода позаимстоваваны из [репозитория](https://github.com/skoltech-nlp/russe_detox_2022) соревнования. 
